import {
  type BaseMessage,
  HumanMessage,
  SystemMessage,
  ToolMessage,
} from "@langchain/core/messages";
import type { ChatOpenAI } from "@langchain/openai";
import { TavilySearch } from "@langchain/tavily";
import { traceable } from "langsmith/traceable";

import { loadEnv } from "@/app/config/env";

import { callResearcher, callSupervisor, callWriter } from "./multiAgent";
import { availableTools, toolsSchema } from "./tools";

const env = loadEnv();

/**
 * å­¦ç¿’ç”¨ã®åŒæœŸå‹Agentã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
 * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ä½¿ã‚ãšã€ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’å«ã‚€ãƒ«ãƒ¼ãƒ—å‡¦ç†ã‚’åŒæœŸçš„ã«è¡Œã„ã¾ã™ã€‚
 *
 * @param chatModel - LangChain ChatOpenAIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
 * @param userQuery - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•
 * @returns æœ€çµ‚çš„ãªAIã®å›ç­”
 */
export const runLearningAgent = async (
  chatModel: ChatOpenAI | null,
  userQuery: string
): Promise<string> => {
  if (!chatModel) {
    return "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚";
  }

  const searchTool = new TavilySearch({
    maxResults: 3,
    tavilyApiKey: env.tavilyApiKey,
  });

  // ãƒ„ãƒ¼ãƒ«ã‚’ãƒã‚¤ãƒ³ãƒ‰
  const modelWithTools = chatModel.bindTools([...toolsSchema, searchTool]);

  // ä¼šè©±å±¥æ­´ã®åˆæœŸåŒ–
  const messages: BaseMessage[] = [
    new SystemMessage(
      `
      ã‚ãªãŸã¯å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
      è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã€åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

      ã€é‡è¦ï¼šæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã€‘
      ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å‰ã€ã¾ãŸã¯å›ç­”ã™ã‚‹å‰ã«ã€å¿…ãšä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã‚ãªãŸã®æ€è€ƒã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

      Thought: [ã“ã“ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã®ç†è§£ã€æ¬¡ã«ã™ã¹ãè¡Œå‹•ã€ãã®ç†ç”±ãªã©ã‚’è¨˜è¿°ã™ã‚‹]

      ä¾‹ï¼š
      Thought: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å¤©æ°—ã‚’çŸ¥ã‚ŠãŸãŒã£ã¦ã„ã‚‹ã€‚å ´æ‰€ã¯æ±äº¬ã ã€‚get_current_weatherãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹ã€‚
      (ãã®å¾Œã«ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—)
      `
    ),
    new HumanMessage(userQuery),
  ];

  const MAX_TURNS = 5; // ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ã®ãŸã‚ã®æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°
  let turnCount = 0;

  while (turnCount < MAX_TURNS) {
    turnCount++;

    // LangChain APIã‚’å‘¼ã³å‡ºã™ï¼ˆåŒæœŸå‡¦ç†ï¼‰
    const response = await modelWithTools.invoke(messages);

    // å±¥æ­´ã«è¿½åŠ 
    messages.push(response);

    // ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚‹å ´åˆ
    if (response.tool_calls && response.tool_calls.length > 0) {
      // å„ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
      for (const toolCall of response.tool_calls) {
        // ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œ
        let result;
        if (toolCall.name === searchTool.name) {
          result = await searchTool.invoke(toolCall.args as any);
        } else {
          const toolFn = availableTools[toolCall.name];
          if (!toolFn) throw new Error(`æœªçŸ¥ã®ãƒ„ãƒ¼ãƒ«: ${toolCall.name}`);
          result = await toolFn(toolCall.args);
        }

        // ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‚’å±¥æ­´ã«è¿½åŠ 
        messages.push(
          new ToolMessage({
            tool_call_id: toolCall.id || "",
            content: JSON.stringify(result),
          })
        );
      }
      // ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¾Œã€æ¬¡ã®ã‚¿ãƒ¼ãƒ³ã¸
      continue;
    }

    // ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒãªã„å ´åˆ = æœ€çµ‚å›ç­”
    let finalContent =
      typeof response.content === "string" ? response.content : JSON.stringify(response.content);

    // "Thought:" ã‹ã‚‰å§‹ã¾ã‚‹æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹éƒ¨åˆ†ã‚’å‰Šé™¤ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯è¦‹ã›ãªã„ï¼‰
    // Thought: ... (æ”¹è¡Œ) ã¾ã§ã‚’å‰Šé™¤
    finalContent = finalContent.replace(/Thought:[\s\S]*?(\n\n|\n|$)/g, "").trim();

    return finalContent;
  }

  // æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ã«é”ã—ãŸå ´åˆ
  return `æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ï¼ˆ${MAX_TURNS}ï¼‰ã«é”ã—ãŸãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚`;
};

/**
 * ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä¸€ã¤ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚
 */
export const runMultiAgentSystem = traceable(
  async (chatModel: ChatOpenAI | null, userQuery: string): Promise<string> => {
    if (!chatModel) {
      return "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚";
    }

    const history: BaseMessage[] = [new HumanMessage(userQuery)];
    let nextAgent = "Supervisor";
    let currentInstruction = "";
    let loopCount = 0;
    const MAX_LOOPS = 10;

    console.log("\nğŸ‘¥ [MultiAgent] System Start");

    while (loopCount < MAX_LOOPS) {
      loopCount++;
      console.log(`\nğŸ”„ [Loop ${loopCount}] Next: ${nextAgent}`);

      if (nextAgent === "Supervisor") {
        const result = await callSupervisor(chatModel, history);

        if (result.next === "FINISH") {
          console.log("ğŸ [MultiAgent] Finished");
          break;
        }

        nextAgent = result.next;
        currentInstruction = result.instruction || "";
      } else if (nextAgent === "Researcher") {
        const result = await callResearcher(chatModel, currentInstruction);

        history.push(new HumanMessage({ name: "Researcher", content: `ã€èª¿æŸ»çµæœã€‘\n${result}` }));
        nextAgent = "Supervisor";
      } else if (nextAgent === "Writer") {
        // historyã‚’æ–‡å­—åˆ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
        const context = history.map((m) => `[${m.name || "User"}]: ${m.content}`).join("\n\n");

        const result = await callWriter(chatModel, context, currentInstruction);

        history.push(new HumanMessage({ name: "Writer", content: result }));
        nextAgent = "Supervisor";
      }
    }

    if (loopCount >= MAX_LOOPS) {
      return "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: ãƒ«ãƒ¼ãƒ—å›æ•°ãŒä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚";
    }

    // æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆWriterã®æˆæœç‰©ãªã©ï¼‰ã‚’è¿”ã™
    const lastMessage = history[history.length - 1];
    return typeof lastMessage.content === "string"
      ? lastMessage.content
      : JSON.stringify(lastMessage.content);
  },
  { name: "MultiAgentSystem" }
);
